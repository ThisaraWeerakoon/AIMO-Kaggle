# AIMO-Kaggle 
The goal of this project is to create algorithms and models that can solve tricky math problems written in LaTeX format.

## Description
Developed a novel approach to fine-tune large language models (LLMs) to enhance their mathematical reasoning capabilities. Implemented answer augmentation by generating multiple reasoning paths for the same mathematical question using few-shot chain-of-thought prompting. Additionally, utilized rephrasing prompting to generate more questions through the LLM and applied backward reasoning to rewrite questions. This comprehensive strategy improved the model's problem-solving accuracy and versatility.

## Steps following
- Enhanced LLMs' mathematical reasoning through fine-tuning.
- Applied few-shot chain-of-thought prompting for multiple reasoning paths.
- Used rephrasing prompting to generate additional questions.
- Incorporated backward reasoning for question rewriting.
- Improved overall accuracy and versatility in mathematical problem-solving.

