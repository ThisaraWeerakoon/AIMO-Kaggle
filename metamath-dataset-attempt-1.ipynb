{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":73231,"databundleVersionId":8365361,"sourceType":"competition"},{"sourceId":8009768,"sourceType":"datasetVersion","datasetId":4717827},{"sourceId":8524712,"sourceType":"datasetVersion","datasetId":4766079},{"sourceId":8803270,"sourceType":"datasetVersion","datasetId":5294244},{"sourceId":27825,"sourceType":"modelInstanceVersion","modelInstanceId":22009}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><img src=\"https://keras.io/img/logo-small.png\" alt=\"Keras logo\" width=\"100\"><br/>\nThis starter notebook is provided by the Keras team.</center>","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# Install Libraries\n\nWe need to install latest KerasNLP to load Gemma 1.1 model. As we don't have access to internet during inference, we will be installing this library from our local files.","metadata":{}},{"cell_type":"code","source":"!pip install -q /kaggle/input/keras-lib-dataset/keras_nlp-0.9.2-py3-none-any.whl --no-deps","metadata":{"execution":{"iopub.status.busy":"2024-06-27T18:20:56.720826Z","iopub.execute_input":"2024-06-27T18:20:56.721266Z","iopub.status.idle":"2024-06-27T18:21:18.896966Z","shell.execute_reply.started":"2024-06-27T18:20:56.721231Z","shell.execute_reply":"2024-06-27T18:21:18.895882Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Requirement '/kaggle/input/keras-lib-dataset/keras_nlp-0.9.2-py3-none-any.whl' looks like a filename, but the file does not exist\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/kaggle/input/keras-lib-dataset/keras_nlp-0.9.2-py3-none-any.whl'\n\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import Libraries ","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"] = \"jax\" # you can also use tensorflow or torch\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.9\" # avoid memory fragmentation on JAX backend.\n\nimport keras\nimport keras_nlp\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\ntqdm.pandas() # progress bar for pandas\n\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom IPython.display import display, Markdown","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-06-27T18:21:18.898915Z","iopub.execute_input":"2024-06-27T18:21:18.899243Z","iopub.status.idle":"2024-06-27T18:21:33.765792Z","shell.execute_reply.started":"2024-06-27T18:21:18.899214Z","shell.execute_reply":"2024-06-27T18:21:33.764575Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-06-27 18:21:23.312542: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-27 18:21:23.312654: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-27 18:21:23.459506: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"class CFG:\n    seed = 42\n    dataset_path = \"/kaggle/input/ai-mathematical-olympiad-prize\"\n    preset = \"gemma_1.1_instruct_2b_en\" # name of pretrained Gemma\n    sequence_length = 512 # max size of input sequence for training\n    batch_size = 1 # size of the input batch in training\n    epochs = 1 # number of epochs to train","metadata":{"execution":{"iopub.status.busy":"2024-06-27T18:21:33.767106Z","iopub.execute_input":"2024-06-27T18:21:33.767804Z","iopub.status.idle":"2024-06-27T18:21:33.773720Z","shell.execute_reply.started":"2024-06-27T18:21:33.767771Z","shell.execute_reply":"2024-06-27T18:21:33.772460Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Reproducibility \nSets value for random seed to produce similar result in each run.","metadata":{}},{"cell_type":"code","source":"keras.utils.set_random_seed(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T18:21:33.776655Z","iopub.execute_input":"2024-06-27T18:21:33.777066Z","iopub.status.idle":"2024-06-27T18:21:33.807390Z","shell.execute_reply.started":"2024-06-27T18:21:33.777027Z","shell.execute_reply":"2024-06-27T18:21:33.806095Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Data\n\nNo training data is provided in this competition; in other words, we can use any openly available datasets for this competition. In this notebook, we will use a modified **Math** dataset which I have compiled to have a `Question-Solution-Answer` format.\n\n**Data Format:**\n\nThese datasets include:\n- `problem`: The math problem in LaTeX format.\n- `solution`: Step-by-step solution to this problem.\n- `answer`: Final answer of the solution which will be the ground truth for this competition.\n- `level`: Difficulty of the problem.\n- `type`: The category of the problem.\n\n> This dataset comes with its own train test split. However, we will merge them both and use them for fine-tuning. You are welcome to use them for trainining and validation separately. Also to reduce the training time we will only be training on the first`1000` samples. You are welcome to train on the full data.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nmeta_math_df=pd.read_csv(\"/kaggle/input/metamath-dataset/MetaMath.csv\")\nmeta_math_df","metadata":{"execution":{"iopub.status.busy":"2024-06-27T18:21:33.808811Z","iopub.execute_input":"2024-06-27T18:21:33.809312Z","iopub.status.idle":"2024-06-27T18:21:41.660202Z","shell.execute_reply.started":"2024-06-27T18:21:33.809274Z","shell.execute_reply":"2024-06-27T18:21:41.659088Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                 type                                              query  \\\n0         MATH_AnsAug  Gracie and Joe are choosing numbers on the com...   \n1       GSM_Rephrased  What is the total cost of purchasing equipment...   \n2              GSM_SV  Diego baked 12 cakes for his sister's birthday...   \n3         MATH_AnsAug            Convert $10101_3$ to a base 10 integer.   \n4           GSM_FOBAR  Sue works in a factory and every 30 minutes, a...   \n...               ...                                                ...   \n394995      GSM_FOBAR  Yesterday, David and William were invited to a...   \n394996    MATH_AnsAug  Suppose $\\sin N = \\frac{2}{3}$ in the diagram ...   \n394997      GSM_FOBAR  Jeff orders a Halloween costume.  He has to pu...   \n394998    MATH_AnsAug  The average age of the 10 females in a choir i...   \n394999     GSM_AnsAug  In a shipping container, there are 10 crates. ...   \n\n                                        original_question  \\\n0       Gracie and Joe are choosing numbers on the com...   \n1       The treasurer of a football team must buy equi...   \n2       Diego baked 12 cakes for his sister's birthday...   \n3                 Convert $10101_3$ to a base 10 integer.   \n4       Sue works in a factory and every 30 minutes, a...   \n...                                                   ...   \n394995  Yesterday, David and William were invited to a...   \n394996  Suppose $\\sin N = \\frac{2}{3}$ in the diagram ...   \n394997  Jeff orders a Halloween costume.  He has to pu...   \n394998  The average age of the 10 females in a choir i...   \n394999  In a shipping container, there are 10 crates. ...   \n\n                                                 response  \n0       The distance between two points $(x_1,y_1)$ an...  \n1       Each player requires a $25 jersey, a $15.20 pa...  \n2       To solve this problem, we need to determine th...  \n3       $10101_3 = 1 \\cdot 3^4 + 0 \\cdot 3^3 + 1 \\cdot...  \n4       We know that every 30 minutes, a machine produ...  \n...                                                   ...  \n394995  David broke 2 glasses.\\nHis friend William bro...  \n394996  We can use the Pythagorean Theorem to find $LN...  \n394997  The costume cost 40% more than last year's cos...  \n394998  The sum of the ages of the 10 females is $10 \\...  \n394999  There are 10 crates in the shipping container....  \n\n[395000 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>query</th>\n      <th>original_question</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MATH_AnsAug</td>\n      <td>Gracie and Joe are choosing numbers on the com...</td>\n      <td>Gracie and Joe are choosing numbers on the com...</td>\n      <td>The distance between two points $(x_1,y_1)$ an...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GSM_Rephrased</td>\n      <td>What is the total cost of purchasing equipment...</td>\n      <td>The treasurer of a football team must buy equi...</td>\n      <td>Each player requires a $25 jersey, a $15.20 pa...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GSM_SV</td>\n      <td>Diego baked 12 cakes for his sister's birthday...</td>\n      <td>Diego baked 12 cakes for his sister's birthday...</td>\n      <td>To solve this problem, we need to determine th...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MATH_AnsAug</td>\n      <td>Convert $10101_3$ to a base 10 integer.</td>\n      <td>Convert $10101_3$ to a base 10 integer.</td>\n      <td>$10101_3 = 1 \\cdot 3^4 + 0 \\cdot 3^3 + 1 \\cdot...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GSM_FOBAR</td>\n      <td>Sue works in a factory and every 30 minutes, a...</td>\n      <td>Sue works in a factory and every 30 minutes, a...</td>\n      <td>We know that every 30 minutes, a machine produ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>394995</th>\n      <td>GSM_FOBAR</td>\n      <td>Yesterday, David and William were invited to a...</td>\n      <td>Yesterday, David and William were invited to a...</td>\n      <td>David broke 2 glasses.\\nHis friend William bro...</td>\n    </tr>\n    <tr>\n      <th>394996</th>\n      <td>MATH_AnsAug</td>\n      <td>Suppose $\\sin N = \\frac{2}{3}$ in the diagram ...</td>\n      <td>Suppose $\\sin N = \\frac{2}{3}$ in the diagram ...</td>\n      <td>We can use the Pythagorean Theorem to find $LN...</td>\n    </tr>\n    <tr>\n      <th>394997</th>\n      <td>GSM_FOBAR</td>\n      <td>Jeff orders a Halloween costume.  He has to pu...</td>\n      <td>Jeff orders a Halloween costume.  He has to pu...</td>\n      <td>The costume cost 40% more than last year's cos...</td>\n    </tr>\n    <tr>\n      <th>394998</th>\n      <td>MATH_AnsAug</td>\n      <td>The average age of the 10 females in a choir i...</td>\n      <td>The average age of the 10 females in a choir i...</td>\n      <td>The sum of the ages of the 10 females is $10 \\...</td>\n    </tr>\n    <tr>\n      <th>394999</th>\n      <td>GSM_AnsAug</td>\n      <td>In a shipping container, there are 10 crates. ...</td>\n      <td>In a shipping container, there are 10 crates. ...</td>\n      <td>There are 10 crates in the shipping container....</td>\n    </tr>\n  </tbody>\n</table>\n<p>395000 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport re\n\n# Function to extract the answer from the text\ndef extract_answer(text):\n    match = re.search(r'The answer is:\\s*(\\d+)', text)\n    if match:\n        answer = int(float(match.group(1)))\n        if answer >= 0:\n            return answer\n    return None\n\n\n\n# Apply the extract_answer function to the column and create a new column 'result'\nmeta_math_df['result'] = meta_math_df['response'].apply(extract_answer)\nmeta_math_df = meta_math_df.dropna(subset=['result'])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-27T18:21:41.661594Z","iopub.execute_input":"2024-06-27T18:21:41.661906Z","iopub.status.idle":"2024-06-27T18:21:42.757661Z","shell.execute_reply.started":"2024-06-27T18:21:41.661879Z","shell.execute_reply":"2024-06-27T18:21:42.756640Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"meta_math_df=meta_math_df[:5000]\nmeta_math_df","metadata":{"execution":{"iopub.status.busy":"2024-06-27T18:21:42.758799Z","iopub.execute_input":"2024-06-27T18:21:42.759098Z","iopub.status.idle":"2024-06-27T18:21:42.775369Z","shell.execute_reply.started":"2024-06-27T18:21:42.759072Z","shell.execute_reply":"2024-06-27T18:21:42.774371Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"               type                                              query  \\\n1     GSM_Rephrased  What is the total cost of purchasing equipment...   \n2            GSM_SV  Diego baked 12 cakes for his sister's birthday...   \n3       MATH_AnsAug            Convert $10101_3$ to a base 10 integer.   \n4         GSM_FOBAR  Sue works in a factory and every 30 minutes, a...   \n5         GSM_FOBAR  Mark is buying asphalt to pave a new section o...   \n...             ...                                                ...   \n5369        MATH_SV  Given any two positive real numbers $x$ and $y...   \n5370         GSM_SV  Fiona and Casey share the hoodies they own. Be...   \n5371     MATH_FOBAR  For a positive integer $p$, define the positiv...   \n5372         GSM_SV  Lucille is painting her room. Two of her walls...   \n5373         GSM_SV  Phyllis has two gardens. In the first garden, ...   \n\n                                      original_question  \\\n1     The treasurer of a football team must buy equi...   \n2     Diego baked 12 cakes for his sister's birthday...   \n3               Convert $10101_3$ to a base 10 integer.   \n4     Sue works in a factory and every 30 minutes, a...   \n5     Mark is buying asphalt to pave a new section o...   \n...                                                 ...   \n5369  Given any two positive real numbers $x$ and $y...   \n5370  Fiona and Casey share the hoodies they own. Be...   \n5371  For a positive integer $p$, define the positiv...   \n5372  Lucille is painting her room. Two of her walls...   \n5373  Phyllis has two gardens. In the first garden, ...   \n\n                                               response  result  \n1     Each player requires a $25 jersey, a $15.20 pa...   752.0  \n2     To solve this problem, we need to determine th...     1.0  \n3     $10101_3 = 1 \\cdot 3^4 + 0 \\cdot 3^3 + 1 \\cdot...    91.0  \n4     We know that every 30 minutes, a machine produ...     1.0  \n5     The area of the road is the length multiplied ...    75.0  \n...                                                 ...     ...  \n5369  To solve this problem, we need to determine th...    19.0  \n5370  To solve this problem, we need to determine th...     2.0  \n5371  We want to find the value of $X$ in the given ...    13.0  \n5372  To solve this problem, we need to determine th...     3.0  \n5373  To solve this problem, we need to determine th...    20.0  \n\n[5000 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>query</th>\n      <th>original_question</th>\n      <th>response</th>\n      <th>result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>GSM_Rephrased</td>\n      <td>What is the total cost of purchasing equipment...</td>\n      <td>The treasurer of a football team must buy equi...</td>\n      <td>Each player requires a $25 jersey, a $15.20 pa...</td>\n      <td>752.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GSM_SV</td>\n      <td>Diego baked 12 cakes for his sister's birthday...</td>\n      <td>Diego baked 12 cakes for his sister's birthday...</td>\n      <td>To solve this problem, we need to determine th...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MATH_AnsAug</td>\n      <td>Convert $10101_3$ to a base 10 integer.</td>\n      <td>Convert $10101_3$ to a base 10 integer.</td>\n      <td>$10101_3 = 1 \\cdot 3^4 + 0 \\cdot 3^3 + 1 \\cdot...</td>\n      <td>91.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GSM_FOBAR</td>\n      <td>Sue works in a factory and every 30 minutes, a...</td>\n      <td>Sue works in a factory and every 30 minutes, a...</td>\n      <td>We know that every 30 minutes, a machine produ...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>GSM_FOBAR</td>\n      <td>Mark is buying asphalt to pave a new section o...</td>\n      <td>Mark is buying asphalt to pave a new section o...</td>\n      <td>The area of the road is the length multiplied ...</td>\n      <td>75.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5369</th>\n      <td>MATH_SV</td>\n      <td>Given any two positive real numbers $x$ and $y...</td>\n      <td>Given any two positive real numbers $x$ and $y...</td>\n      <td>To solve this problem, we need to determine th...</td>\n      <td>19.0</td>\n    </tr>\n    <tr>\n      <th>5370</th>\n      <td>GSM_SV</td>\n      <td>Fiona and Casey share the hoodies they own. Be...</td>\n      <td>Fiona and Casey share the hoodies they own. Be...</td>\n      <td>To solve this problem, we need to determine th...</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>5371</th>\n      <td>MATH_FOBAR</td>\n      <td>For a positive integer $p$, define the positiv...</td>\n      <td>For a positive integer $p$, define the positiv...</td>\n      <td>We want to find the value of $X$ in the given ...</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>5372</th>\n      <td>GSM_SV</td>\n      <td>Lucille is painting her room. Two of her walls...</td>\n      <td>Lucille is painting her room. Two of her walls...</td>\n      <td>To solve this problem, we need to determine th...</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>5373</th>\n      <td>GSM_SV</td>\n      <td>Phyllis has two gardens. In the first garden, ...</td>\n      <td>Phyllis has two gardens. In the first garden, ...</td>\n      <td>To solve this problem, we need to determine th...</td>\n      <td>20.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Prompt Engineering\n\nWe will be using below simple prompt template we'll use to create problem-solution-answer trio to feed the model. This template will help the model to follow instruction and respond accurately. You can explore more advanced prompt templates for better results. \n\n```\nRole:\nYou are an advanced AI system with exceptional mathematical reasoning and problem-solving capabilities, specifically designed to solve tricky math problems (whose answer is a non-negative integer) written in LaTeX format from the AI Mathematical Olympiad (AIMO) competition. Your task is to accurately analyze and solve intricate mathematical problems, demonstrating a deep understanding of mathematical concepts and a strong ability to apply logical reasoning strategies.\n\nInstruction:\n1. Carefully read and comprehend the problem statement provided in the \"Problem\" section.\n2. In the \"Solution\" section, provide a solution of the problem with detailed explanation of your logical reasoning process. Keep in mind that answer must be a non-negative integer number.\n3. At the end, create a \"Answer\" section where you will state only the final numerical or algebraic answer, without any additional text or narrative.\n\nProblem:\n...\n\nSolution:\n...\n\nAnswer:\n...\n```","metadata":{}},{"cell_type":"code","source":"template = \"\"\"Role:\\nYou are an advanced AI system with exceptional mathematical reasoning and problem-solving capabilities, specifically designed to solve tricky math problems (whose answer is a non-negative integer) written in LaTeX format from the AI Mathematical Olympiad (AIMO) competition. Your task is to accurately analyze and solve intricate mathematical problems, demonstrating a deep understanding of mathematical concepts and a strong ability to apply logical reasoning strategies.\\n\\nInstruction:\n1. Carefully read and comprehend the problem statement provided in the \"Problem\" section.\n2. In the \"Solution\" section, provide a solution of the problem with detailed explanation of your logical reasoning process. Keep in mind that answer must be a non-negative integer number.\n3. At the end, create a \"Answer\" section where you will state only the final numerical or algebraic answer, without any additional text or narrative.\\n\\nProblem:\\n{problem}\\n\\nSolution:\\n{solution}\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-06-27T18:21:42.776543Z","iopub.execute_input":"2024-06-27T18:21:42.776874Z","iopub.status.idle":"2024-06-27T18:21:42.786298Z","shell.execute_reply.started":"2024-06-27T18:21:42.776840Z","shell.execute_reply":"2024-06-27T18:21:42.785334Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"meta_math_df[\"prompt\"] = meta_math_df.progress_apply(lambda row: template.format(problem=row.query,\n                                                             solution=f\"{row.response}\\n\\nAnswer:\\n{row.result}\"),\n                                                             axis=1)\nmeta_math_df = meta_math_df.prompt.tolist()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T18:21:42.787471Z","iopub.execute_input":"2024-06-27T18:21:42.787774Z","iopub.status.idle":"2024-06-27T18:21:43.030082Z","shell.execute_reply.started":"2024-06-27T18:21:42.787749Z","shell.execute_reply":"2024-06-27T18:21:43.029193Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9c4ad00464848ecb098850c3cc13e0c"}},"metadata":{}}]},{"cell_type":"markdown","source":"Let's examine a sample prompt. As the answers in our dataset are curated with **markdown** format, we will render the sample using `Markdown()` to properly visualize the formatting.","metadata":{}},{"cell_type":"markdown","source":"## Check Sample","metadata":{}},{"cell_type":"markdown","source":"## Sample 1","metadata":{}},{"cell_type":"markdown","source":"## Sample 2","metadata":{}},{"cell_type":"markdown","source":"# Modeling\n\n<div align=\"center\"><img src=\"https://i.ibb.co/Bqg9w3g/Gemma-Logo-no-background.png\" width=\"300\"></div>\n\n**Gemma** is a collection of advanced open LLMs developed by **Google DeepMind** and other **Google teams**, derived from the same research and technology behind the **Gemini** models. They can be integrated into applications and run on various platforms including mobile devices and hosted services. Developers can customize Gemma models using tuning techniques to enhance their performance for specific tasks, offering more targeted and efficient generative AI solutions beyond text generation.\n\nGemma models are available in several sizes so we can build generative AI solutions based on your available computing resources, the capabilities you need, and where you want to run them.\n\n| Parameters size | Tuned versions    | Intended platforms                 | Preset                 |\n|-----------------|-------------------|------------------------------------|------------------------|\n| 2B              | Pretrained        | Mobile devices and laptops         | `gemma_2b_en`          |\n| 2B              | Instruction tuned | Mobile devices and laptops         | `gemma_1.1_instruct_2b_en` |\n| 2B              | Pretrained        | Code Completion in Mobile Device   | `code_gemma_2b_en` |\n| 7B              | Pretrained        | Desktop computers and small servers| `gemma_7b_en`          |\n| 7B              | Instruction tuned | Desktop computers and small servers| `gemma_1.1_instruct_7b_en` |\n| 7B              | Instruction tuned | Code Completion in Desktop computers| `code_gemma_7b_en` |\n\nIn this notebook, we will utilize the `Gemma 1.1 2b-it` model from KerasNLP's pretrained models to solve the math olympiad questions. We are using the \"Instruction tuned\" model instead of the \"Pretrained\" one because it is easier for the model to fine-tune on the prepared dataset. \n\nTo explore other available models, you can simply adjust the `preset` value in the `CFG` (config). You can find a list of other pretrained models on the [KerasNLP website](https://keras.io/api/keras_nlp/models/).","metadata":{}},{"cell_type":"markdown","source":"## Gemma Causal LM\n\nThe code below will build an end-to-end Gemma model for causal language modeling (hence the name `GemmaCausalLM`). A causal language model (LM) predicts the next token based on previous tokens. This task setup can be used to train the model unsupervised on plain text input or to autoregressively generate plain text similar to the data used for training. This task can be used for pre-training or fine-tuning a Gemma model simply by calling `fit()`.\n\nThis model has a `generate()` method, which generates text based on a prompt. The generation strategy used is controlled by an additional sampler argument on `compile()`. You can recompile the model with different `keras_nlp.samplers` objects to control the generation. By default, `\"greedy\"` sampling will be used.\n\n> The `from_preset` method instantiates the model from a preset architecture and weights.","metadata":{}},{"cell_type":"code","source":"gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(CFG.preset)\ngemma_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T18:21:43.033375Z","iopub.execute_input":"2024-06-27T18:21:43.033673Z","iopub.status.idle":"2024-06-27T18:22:47.170305Z","shell.execute_reply.started":"2024-06-27T18:21:43.033648Z","shell.execute_reply":"2024-06-27T18:22:47.169339Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'task.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'preprocessor.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nnormalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"## Gemma LM Preprocessor\n\nAn important part of the Gemma model is the **Preprocessor** layer, which under the hood uses **Tokenizer**.\n\n**What it does:** The preprocessor takes input strings and transforms them into a dictionary (`token_ids`, `padding_mask`) containing preprocessed tensors. This process starts with tokenization, where input strings are converted into sequences of token IDs.\n\n**Why it's important:** Initially, raw text data is complex and challenging for modeling due to its high dimensionality. By converting text into a compact set of tokens, such as transforming `\"The quick brown fox\"` into `[\"the\", \"qu\", \"##ick\", \"br\", \"##own\", \"fox\"]`, we simplify the data. Many models rely on special tokens and additional tensors to understand input. These tokens help divide input and identify padding, among other tasks. Making all sequences the same length through padding boosts computational efficiency, making subsequent steps smoother.\n\nExplore the following pages to access the available preprocessing and tokenizer layers in **KerasNLP**:\n- [Preprocessing](https://keras.io/api/keras_nlp/preprocessing_layers/)\n- [Tokenizers](https://keras.io/api/keras_nlp/tokenizers/)","metadata":{}},{"cell_type":"code","source":"meta_math_df[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-27T18:22:47.171405Z","iopub.execute_input":"2024-06-27T18:22:47.171692Z","iopub.status.idle":"2024-06-27T18:22:47.177787Z","shell.execute_reply.started":"2024-06-27T18:22:47.171667Z","shell.execute_reply":"2024-06-27T18:22:47.176873Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'Role:\\nYou are an advanced AI system with exceptional mathematical reasoning and problem-solving capabilities, specifically designed to solve tricky math problems (whose answer is a non-negative integer) written in LaTeX format from the AI Mathematical Olympiad (AIMO) competition. Your task is to accurately analyze and solve intricate mathematical problems, demonstrating a deep understanding of mathematical concepts and a strong ability to apply logical reasoning strategies.\\n\\nInstruction:\\n1. Carefully read and comprehend the problem statement provided in the \"Problem\" section.\\n2. In the \"Solution\" section, provide a solution of the problem with detailed explanation of your logical reasoning process. Keep in mind that answer must be a non-negative integer number.\\n3. At the end, create a \"Answer\" section where you will state only the final numerical or algebraic answer, without any additional text or narrative.\\n\\nProblem:\\nWhat is the total cost of purchasing equipment for all sixteen players on the football team, considering that each player requires a $25 jersey, a $15.20 pair of shorts, and a pair of socks priced at $6.80?\\n\\nSolution:\\nEach player requires a $25 jersey, a $15.20 pair of shorts, and a pair of socks priced at $6.80.\\nSo the total cost for each player is $25 + $15.20 + $6.80 = $47.\\nSince there are sixteen players on the football team, the total cost for all of them is 16 * $47 = $752.\\n#### 752\\nThe answer is: 752\\n\\nAnswer:\\n752.0'"},"metadata":{}}]},{"cell_type":"code","source":"x, y, sample_weight = gemma_lm.preprocessor(meta_math_df[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T18:22:47.178896Z","iopub.execute_input":"2024-06-27T18:22:47.179200Z","iopub.status.idle":"2024-06-27T18:22:47.504306Z","shell.execute_reply.started":"2024-06-27T18:22:47.179170Z","shell.execute_reply":"2024-06-27T18:22:47.503426Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"This preprocessing layer will take in batches of strings, and return outputs in a `(x, y, sample_weight)` format, where the `y` label is the next token id in the `x` sequence.\n\nFrom the code below, we can see that, after the preprocessor, the data shape is `(num_samples, sequence_length)`.","metadata":{}},{"cell_type":"code","source":"x","metadata":{"execution":{"iopub.status.busy":"2024-06-27T18:22:47.505789Z","iopub.execute_input":"2024-06-27T18:22:47.506622Z","iopub.status.idle":"2024-06-27T18:22:47.513935Z","shell.execute_reply.started":"2024-06-27T18:22:47.506585Z","shell.execute_reply":"2024-06-27T18:22:47.513017Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'token_ids': Array([     2,  11071, 235292, ...,      0,      0,      0], dtype=int32),\n 'padding_mask': Array([ True,  True,  True, ..., False, False, False], dtype=bool)}"},"metadata":{}}]},{"cell_type":"code","source":"# Display the shape of each processed output\nfor k, v in x.items():\n    print(k, \":\", v.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T18:22:47.515185Z","iopub.execute_input":"2024-06-27T18:22:47.515457Z","iopub.status.idle":"2024-06-27T18:22:47.522987Z","shell.execute_reply.started":"2024-06-27T18:22:47.515434Z","shell.execute_reply":"2024-06-27T18:22:47.521782Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"token_ids : (8192,)\npadding_mask : (8192,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Inference before Fine-Tuning\n\nBefore we do fine-tuning, let's see how Gemma model responds with some prepared prompts.\n\n> As this model is not yet fine-tuned for instruction, you will notice that the model's responses are inaccurate.","metadata":{}},{"cell_type":"markdown","source":"## Sample 1","metadata":{}},{"cell_type":"markdown","source":"## Sample 2","metadata":{}},{"cell_type":"markdown","source":"# Fine-tuning with LoRA\n\nTo get better responses from the model, we will fine-tune the model with Low Rank Adaptation (LoRA).\n\n**What exactly is LoRA?**\n\nLoRA is a method used to fine-tune large language models (LLMs) in an efficient way. It involves freezing the weights of the LLM and injecting trainable rank-decomposition matrices.\n\nImagine in an LLM, we have a pre-trained dense layer, represented by a $d \\times d$ weight matrix, denoted as $W_0$. We then initialize two additional dense layers, labeled as $A$ and $B$, with shapes $d \\times r$ and $r \\times d$, respectively. Here, $r$ denotes the rank, which is typically **much smaller than** $d$. Prior to LoRA, the model's output was computed using the equation $output = W_0 \\cdot x + b_0$, where $x$ represents the input and $b_0$ denotes the bias term associated with the original dense layer, which remains frozen. After applying LoRA, the equation becomes $output = (W_0 \\cdot x + b_0) + (B \\cdot A \\cdot x)$, where $A$ and $B$ denote the trainable rank-decomposition matrices that have been introduced.\n\n<center><img src=\"https://i.ibb.co/DWsbhLg/LoRA.png\" width=\"300\"><br/>\nCredit: <a href=\"https://arxiv.org/abs/2106.09685\">LoRA: Low-Rank Adaptation of Large Language Models</a> Paper</center>\n\n\nIn the LoRA paper, $A$ is initialized with $\\mathcal{N} (0, \\sigma^2)$ and $B$ with $0$, where $\\mathcal{N}$ denotes the normal distribution, and $\\sigma^2$ is the variance.\n\n**Why does LoRA save memory?**\n\nEven though we're adding more layers to the model with LoRA, it actually helps save memory. This is because the smaller layers (A and B) have fewer parameters to learn compared to the big model and fewer trainable parameters mean fewer optimizer variables to store. So, even though the overall model might seem bigger, it's actually more efficient in terms of memory usage. \n\n> This notebook uses a LoRA rank of `4`. A higher rank means more detailed changes are possible, but also means more trainable parameters.","metadata":{}},{"cell_type":"code","source":"# Enable LoRA for the model and set the LoRA rank to 4.\ngemma_lm.backbone.enable_lora(rank=64)\ngemma_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T18:22:47.524126Z","iopub.execute_input":"2024-06-27T18:22:47.524419Z","iopub.status.idle":"2024-06-27T18:22:47.833536Z","shell.execute_reply.started":"2024-06-27T18:22:47.524396Z","shell.execute_reply":"2024-06-27T18:22:47.832714Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,527,995,904\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,527,995,904</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,527,995,904\u001b[0m (9.42 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,527,995,904</span> (9.42 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,823,488\u001b[0m (83.25 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,823,488</span> (83.25 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"**Notice** that, the number of trainable parameters is reduced from ~$2.5$ billions to ~$1.3$ millions after enabling LoRA.","metadata":{}},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"# Limit the input sequence length to 512 (to control memory usage).\ngemma_lm.preprocessor.sequence_length = CFG.sequence_length \n\n# Compile the model with loss, optimizer, and metric\ngemma_lm.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=keras.optimizers.Adam(learning_rate=2e-5),\n    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)\n\n# Train model\ngemma_lm.fit(meta_math_df, epochs=CFG.epochs, batch_size=CFG.batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T18:22:47.834738Z","iopub.execute_input":"2024-06-27T18:22:47.835045Z","iopub.status.idle":"2024-06-27T19:24:12.783067Z","shell.execute_reply.started":"2024-06-27T18:22:47.835019Z","shell.execute_reply":"2024-06-27T19:24:12.781979Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3683s\u001b[0m 733ms/step - loss: 0.4851 - sparse_categorical_accuracy: 0.8608\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7b938425a9b0>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Inference after fine-tuning\n\nLet's see how our fine-tuned model responds to the same questions we asked before fine-tuning the model.","metadata":{}},{"cell_type":"markdown","source":"## Sample 1","metadata":{}},{"cell_type":"markdown","source":"## Sample 2","metadata":{}},{"cell_type":"markdown","source":"# AIMO Data\n\nSo far we have inferred our model on **Math** dataset but now let's see how our model perform on AIMO (competition) dataset.","metadata":{}},{"cell_type":"markdown","source":"## Utilities","metadata":{}},{"cell_type":"code","source":"import re\n\n# Extract answer from model response\ndef get_answer(text):\n    try:\n        answer = re.search(r'Answer:\\s*([\\s\\S]+)', text).group(1).strip()\n        answer = answer.replace(\",\",\"\")\n        if is_integer(answer):\n            return int(answer)%1000\n        else:\n            return 0\n    except:\n        return 0\n    \n    \ndef infer(df):\n    preds = []\n    for i in tqdm(range(len(df))):\n        row = df.iloc[i]\n\n        # Generate Prompt using template\n        prompt = template.format(\n            problem=row.problem,\n            solution=\"\"\n        )\n\n        # Infer\n        output = gemma_lm.generate(prompt, max_length=1024)\n        pred = get_answer(output)\n\n        # Store predictions\n        preds.append([row.id, pred])\n        if \"answer\" in row:\n            preds[-1] += [row.answer]\n    return preds","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-27T19:24:12.784471Z","iopub.execute_input":"2024-06-27T19:24:12.784809Z","iopub.status.idle":"2024-06-27T19:24:12.795311Z","shell.execute_reply.started":"2024-06-27T19:24:12.784774Z","shell.execute_reply":"2024-06-27T19:24:12.794225Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Inference on AIMO Data","metadata":{}},{"cell_type":"code","source":"aimo_df = pd.read_csv(f\"{CFG.dataset_path}/train.csv\")\ntrain_preds = infer(aimo_df)\ntrain_pred_df = pd.DataFrame(train_preds, columns=[\"id\", \"prediction\", \"answer\"])\ntrain_pred_df","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-06-27T19:24:12.796657Z","iopub.execute_input":"2024-06-27T19:24:12.797035Z","iopub.status.idle":"2024-06-27T19:25:44.047860Z","shell.execute_reply.started":"2024-06-27T19:24:12.797000Z","shell.execute_reply":"2024-06-27T19:25:44.046896Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eab4116afc8f4f18b9eaf4dfc2b384eb"}},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"       id  prediction  answer\n0  229ee8           0      52\n1  246d26           0     250\n2  2fc4ad           0     702\n3  430b63           0     800\n4  5277ed           0     211\n5  739bc9           0     199\n6  82e2a0           0     185\n7  8ee6f3           0     320\n8  bedda4           0     480\n9  d7e9c9           0     199","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prediction</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>229ee8</td>\n      <td>0</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>246d26</td>\n      <td>0</td>\n      <td>250</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2fc4ad</td>\n      <td>0</td>\n      <td>702</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>430b63</td>\n      <td>0</td>\n      <td>800</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5277ed</td>\n      <td>0</td>\n      <td>211</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>739bc9</td>\n      <td>0</td>\n      <td>199</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>82e2a0</td>\n      <td>0</td>\n      <td>185</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8ee6f3</td>\n      <td>0</td>\n      <td>320</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>bedda4</td>\n      <td>0</td>\n      <td>480</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>d7e9c9</td>\n      <td>0</td>\n      <td>199</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"markdown","source":"## Infer on Test Data","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv(f\"{CFG.dataset_path}/test.csv\")\ntest_preds = infer(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T19:25:44.049231Z","iopub.execute_input":"2024-06-27T19:25:44.049683Z","iopub.status.idle":"2024-06-27T19:25:51.188108Z","shell.execute_reply.started":"2024-06-27T19:25:44.049647Z","shell.execute_reply":"2024-06-27T19:25:51.187106Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70ff9d994cf54a02ad7ac955fd7d3698"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Prepare Submission File\n\nWhile preparing the submission file, we must keep in mind that, the answer must be between `0-999`. This can easily handled by using `remainder (%)` operation. For this notebook, this step is already applied in the inference stage while extracting `answer` from `solution`. So, we don't need to separately apply it heer.","metadata":{}},{"cell_type":"code","source":"sub_df = pd.DataFrame(test_preds, columns=[\"id\", \"answer\"])\n\nsub_df.to_csv('submission.csv',index=False,mode='a',header=True)\nsub_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T19:25:51.189498Z","iopub.execute_input":"2024-06-27T19:25:51.190132Z","iopub.status.idle":"2024-06-27T19:25:51.203993Z","shell.execute_reply.started":"2024-06-27T19:25:51.190095Z","shell.execute_reply":"2024-06-27T19:25:51.203126Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"       id  answer\n0  000aaa       0\n1  111bbb       0\n2  222ccc       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000aaa</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>111bbb</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>222ccc</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Conclusion\n\nWe can see that after fine-tuning, the model is following instructions more accurately. However, it may still struggle to solve problems accurately, which can be attributed to its small size. Nevertheless, there is ample room for improvement. Here are some tips to enhance performance:\n\n- Train on the full data instead of first `1000` samples.\n- Try using the non-instruction-tuned version of Gemma.\n- Increase the `sequence_length`.\n- Experiment with advanced prompt engineering techniques.\n- Implement augmentation to increase the number of samples.\n- Utilize a learning rate scheduler.","metadata":{}},{"cell_type":"markdown","source":"# Reference\n* [Fine-tune Gemma models in Keras using LoRA](https://www.kaggle.com/code/nilaychauhan/fine-tune-gemma-models-in-keras-using-lora)\n* [Parameter-efficient fine-tuning of GPT-2 with LoRA](https://keras.io/examples/nlp/parameter_efficient_finetuning_of_gpt2_with_lora/)\n* [Gemma - KerasNLP](https://keras.io/api/keras_nlp/models/gemma/)","metadata":{}}]}